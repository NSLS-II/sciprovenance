{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**...the next morning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Startup databrokers and elastic search\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "from pprint import pprint\n",
    "\n",
    "from rapidz.graph import _clean_text, readable_graph\n",
    "from xpdan.vend.callbacks.core import Retrieve\n",
    "from xpdan.vend.callbacks.zmq import Publisher\n",
    "from xpdconf.conf import glbl_dict\n",
    "\n",
    "from databroker_elasticsearch import load_elasticindex\n",
    "from databroker_elasticsearch.brokersearch import BrokerSearch\n",
    "\n",
    "from databroker import Broker\n",
    "import yaml\n",
    "import esconverters\n",
    "\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "FYI, the objects we have connected are  \n",
    "1. databoker databases that contain the metadata about the scans\n",
    "2. elastic-search indexes that have indexed the databrokers and will return just the metadata if queried\n",
    "3. Broker-search objects that will return the run-start header objects when queried (this is what is needed to run the analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol wakes up and wonders how CJ did last night, but CJ is now sleeping soundly in his bed\n",
    "1. Pavol wants to use elastic search to search the database of collected data and see how CJ did last night\n",
    "1. He searches for ``tooth`` in any of the metadata fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# query raw es for tooth\n",
    "[d['_source']['sample_name'] for d in raw_es.qsearch('tooth')['hits']['hits']]  # search all fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. He finds three datasets, so he knows that CJ had a successful night\n",
    "1. He checks all the datasets ran to completion\n",
    "1. He also has other ways to search for the dinosaur tooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "for hdr in raw_db_es('tooth'):\n",
    "    print(hdr.stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "raw_es.qsearch('dinosaur')  # search all fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "raw_es.qsearch('sample_name:dinosaur')  # search specific field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "raw_es.qsearch('dino*')  # glob-like search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "raw_es.qsearch('dinosaurus~2')  # fuzzy search max edit distance of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "raw_hdr = next(iter(raw_db_es('dinosaurus~2')))\n",
    "uid = raw_hdr.start['uid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol also wants to know if CJ was able to do any analysis on the data during the night\n",
    "1. Pavol searches the databroker that contains analyzed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# queries with an_es\n",
    "an_es.qsearch('img_sinogram', size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "an_es.qsearch('img_sinogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "an_es.qsearch(f'puid:{uid[:6]}*')  # word in puid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "an_es.qsearch('analysis_stage:img_sinogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "an_es.qsearch('usednodes.ndfunc:*sort_sinogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "an_es.qsearch('gridrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "an_es.qsearch('usednodes.ndkwargs.algorithm:gridrec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol wants to know if there was a tomographic reconstruction already done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# query an_es/databroker for tomo recon\n",
    "hdrs = an_db_es('analysis_stage:*tomo*')\n",
    "tomo_analysis_hdr = next(iter(hdrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Now Pavol wants to replay the same analysis from the database as a sanity check to see if he gets the same answer.\n",
    "1. He wants to see exactly what analysis CJ did during the night, so he plots the analysis graph that he found in the database from the analysis done last night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load and show the graph\n",
    "from shed.replay import replay\n",
    "\n",
    "# load the replay\n",
    "graph, parents, data, vs = replay(raw_db, tomo_analysis_hdr)\n",
    "\n",
    "# make the graph more accessible to humans by renaming things\n",
    "# these names *should* match the names in the graph plot\n",
    "for k, v in graph.nodes.items():\n",
    "    v.update(label=_clean_text(str(v['stream'])).strip())\n",
    "graph = readable_graph(graph)\n",
    "\n",
    "# plot the graph\n",
    "graph.nodes['data img FromEventStream']['stream'].visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Each unique analysis has its own unique id.\n",
    "2. Each unique graph has its own unique id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hdrs = list(an_db_es('usednodes.ndkwargs.algorithm:gridrec'))\n",
    "for hdr in hdrs:\n",
    "    print('analysis id:', hdr.start['uid'])\n",
    "for hdr in hdrs:\n",
    "    print('graph id:', hdr.start['graph_hash'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a publisher to send over to data viz and capture\n",
    "p = Publisher(glbl_dict['inbound_proxy_address'], prefix=b'tomo')\n",
    "z = graph.nodes['img_tomo ToEventStream']['stream'].LastCache().DBFriendly()\n",
    "z.starsink(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. As a sanity check, Pavol replays the analysis from last night with no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# replay analysis with no changes\n",
    "r = Retrieve(dbs['raw'].reg.handler_reg)\n",
    "for v in vs:\n",
    "    d = data[v['uid']]\n",
    "    dd = r(*d)\n",
    "    parents[v[\"node\"]].update(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol now changes the recostruction algorithm to ``algebraic``.  It is the node called ``recon_wrapper`` and he wants the keyword argument ``algorithm`` to be set to ``'art'`` which selects the reconstruction algorithm we want to use.\n",
    "1. He then reruns the analysis through the new pipeline, which has just changed by one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# change to Algebraic Reconstruction technique\n",
    "print(graph.nodes['starmap; recon_wrapper']['stream'].kwargs)\n",
    "graph.nodes['starmap; recon_wrapper']['stream'].kwargs['algorithm'] = 'art'\n",
    "print(graph.nodes['starmap; recon_wrapper']['stream'].kwargs)\n",
    "\n",
    "# replay with changes\n",
    "r = Retrieve(dbs['raw'].reg.handler_reg)\n",
    "for v in vs:\n",
    "    d = data[v['uid']]\n",
    "    dd = r(*d)\n",
    "    parents[v[\"node\"]].update(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Just because he can, Pavol compares the ID of the previous graph and the new one.  They are different because the graphs are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# These hashes are different because the algorithms are different\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))\n",
    "from databroker_elasticsearch.converters import register_converter\n",
    "\n",
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)\n",
    "\n",
    "print(an_db[-1].start['graph_hash'])\n",
    "print(an_db[-2].start['graph_hash'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol searches elastic search for the art reconstruction data\n",
    "1. Not surprisingly, Pavol wants to compare the previous analysis to the new one.\n",
    "1. To do this, he retrieves the last event from each stream and plots them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# an_es for new data (via new recon algo)\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))\n",
    "from databroker_elasticsearch.converters import register_converter\n",
    "\n",
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)\n",
    "vqan = lambda q: pprint((q, an_es.qsearch(q)))\n",
    "\n",
    "an_es.qsearch('art')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr1 = next(iter(an_db_es('usednodes.ndkwargs.algorithm:art')))\n",
    "hdr2 = next(iter(an_db_es('usednodes.ndkwargs.algorithm:gridrec')))\n",
    "\n",
    "art = next(hdr1.data('img_tomo', stream_name='final_primary'))\n",
    "grid = next(hdr2.data('img_tomo', stream_name='final_primary'))\n",
    "\n",
    "# Compare results\n",
    "fig, axs = plt.subplots(1, 3, tight_layout=True)\n",
    "for img, ax in zip([art, grid], axs):\n",
    "    ax.imshow(img)\n",
    "axs[-1].imshow(art - grid)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
