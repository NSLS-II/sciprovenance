{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**...the next morning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Startup databrokers and elastic search\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "from pprint import pprint\n",
    "\n",
    "from rapidz.graph import _clean_text, readable_graph\n",
    "from xpdan.vend.callbacks.core import Retrieve\n",
    "from xpdan.vend.callbacks.zmq import Publisher\n",
    "from xpdconf.conf import glbl_dict\n",
    "\n",
    "from databroker_elasticsearch import load_elasticindex\n",
    "from databroker_elasticsearch.brokersearch import BrokerSearch\n",
    "\n",
    "from databroker import Broker\n",
    "import yaml\n",
    "import esconverters\n",
    "\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "FYI, the objects we have connected are  \n",
    "1. databoker databases that contain the metadata about the scans\n",
    "2. elastic-search indexes that have indexed the databrokers and will return just the metadata if queried\n",
    "3. Broker-search objects that will return the run-start header objects when queried (this is what is needed to run the analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol wakes up and wonders how CJ did last night, but CJ is now sleeping soundly in his bed\n",
    "1. Pavol wants to use elastic search to search the database of collected data and see how CJ did last night\n",
    "1. He searches for ``tooth`` in any of the metadata fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# query raw es for dino tooth\n",
    "raw_es.qsearch()\n",
    "vqraw = lambda q: pprint((q, raw_es.qsearch(q)))\n",
    "vqraw('tooth')  # search all fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. He finds three datasets, so he knows that CJ had a successful night\n",
    "1. He checks all the datasets ran to completion [FIXME]\n",
    "1. He also has other ways to search for the dinosaur tooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "vqraw('dinosaur')  # search all fields\n",
    "vqraw('sample_name:dinosaur')  # search specific field\n",
    "vqraw('dino*')  # glob-like search\n",
    "vqraw('dinosaurus~2')  # fuzzy search max edit distance of 2\n",
    "raw_hdr = next(iter(raw_db_es('dinosaurus~2')))\n",
    "uid = raw_hdr.start['uid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol also wants to know if CJ was able to do any analysis on the data during the night\n",
    "1. Pavol searches the databroker that contains analyzed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# queries with an_es\n",
    "vqan = lambda q: pprint((q, an_es.qsearch(q)))\n",
    "vqan('img_sinogram')\n",
    "vqan(f'puid:{uid[:6]}*')  # word in puid\n",
    "vqan('analysis_stage:img_sinogram')\n",
    "vqan('usednodes.ndfunc:*sort_sinogram')\n",
    "# query the algorithm kwarg\n",
    "vqan('gridrec')\n",
    "vqan('usednodes.ndkwargs.algorithm:gridrec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol wants to know if there was a tomographic reconstruction already done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# query an_es/databroker for tomo recon\n",
    "hdrs = an_db_es('analysis_stage:*tomo*')\n",
    "tomo_analysis_hdr = next(iter(hdrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Now Pavol wants to replay the same analysis from the database as a sanity check to see if he gets the same answer.\n",
    "1. He wants to see exactly what analysis CJ did during the night, so he plots the analysis graph that he found in the database from the analysis done last night.  Each unique analysis has its own unique hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# load and show the graph\n",
    "from shed.replay import replay\n",
    "from shed.translation import merkle_hash\n",
    "\n",
    "# load the replay\n",
    "graph, parents, data, vs = replay(raw_db, tomo_analysis_hdr)\n",
    "\n",
    "# make the graph more accessible to humans by renaming things\n",
    "# these names *should* match the names in the graph plot\n",
    "for k, v in graph.nodes.items():\n",
    "    v.update(label=_clean_text(str(v['stream'])).strip())\n",
    "graph = readable_graph(graph)\n",
    "\n",
    "# plot the graph\n",
    "graph.nodes['data img FromEventStream']['stream'].visualize()\n",
    "# look at the graph ids\n",
    "# The two pipelines are different because one has the sinogram data processing as wellb\n",
    "old_hash = tomo_analysis_hdr.start['graph_hash']\n",
    "print(old_hash)\n",
    "current_hash = merkle_hash(graph.node[tomo_analysis_hdr.start['outbound_node']]['stream'])\n",
    "print(current_hash)\n",
    "\n",
    "# setup a publisher to send over to data viz and capture\n",
    "p = Publisher(glbl_dict['inbound_proxy_address'], prefix=b'tomo')\n",
    "z = graph.nodes['img_tomo ToEventStream']['stream'].LastCache().DBFriendly()\n",
    "z.starsink(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. As a sanity check, Pavol replays the analysis from last night with no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# replay analysis with no changes\n",
    "r = Retrieve(dbs['raw'].reg.handler_reg)\n",
    "for v in vs:\n",
    "    d = data[v['uid']]\n",
    "    dd = r(*d)\n",
    "    parents[v[\"node\"]].update(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The databases have updated so we need to reload the variables in memory with that information in.  This may be done automatically in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Look at the hash of the graph loaded and what is recorded in the database\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))\n",
    "from databroker_elasticsearch.converters import register_converter\n",
    "\n",
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)\n",
    "\n",
    "print(an_db[-1].start['graph_hash'])\n",
    "print(current_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Pavol now changes the recostruction algorithm to ``algebraic``.  It is the node called ``recon_wrapper`` and he wants the keyword argument ``algorithm`` to be set to ``'art'`` which selects the reconstruction algorithm we want to use.\n",
    "1. He then reruns the analysis through the new pipeline, which has just changed by one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# change to Algebraic Reconstruction technique\n",
    "print(graph.nodes['starmap; recon_wrapper']['stream'].kwargs)\n",
    "graph.nodes['starmap; recon_wrapper']['stream'].kwargs['algorithm'] = 'art'\n",
    "print(graph.nodes['starmap; recon_wrapper']['stream'].kwargs)\n",
    "\n",
    "# replay with changes\n",
    "r = Retrieve(dbs['raw'].reg.handler_reg)\n",
    "for v in vs:\n",
    "    d = data[v['uid']]\n",
    "    dd = r(*d)\n",
    "    parents[v[\"node\"]].update(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Just because he can, Pavol compares the ID of the previous analysis and the new one.  They are different because the analyses are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# These hashes are different because the algorithms are different\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))\n",
    "from databroker_elasticsearch.converters import register_converter\n",
    "\n",
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)\n",
    "\n",
    "print(an_db[-1].start['graph_hash'])\n",
    "print(current_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Not surprisingly, Pavol wants to compare the previous analysis to the new one.\n",
    "1. To do this, he retrieves the last event from each stream and plots them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# an_es for new data (via new recon algo)\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))\n",
    "from databroker_elasticsearch.converters import register_converter\n",
    "\n",
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)\n",
    "vqan = lambda q: pprint((q, an_es.qsearch(q)))\n",
    "\n",
    "vqan('art')\n",
    "\n",
    "# Show the difference between the grid and art reconstructions\n",
    "dbs = {}\n",
    "for yaml_file in ['raw', 'an']:\n",
    "    with open(f'{yaml_file}.yml', 'r') as f:\n",
    "        dbs[yaml_file] = Broker.from_config(yaml.load(f))\n",
    "from databroker_elasticsearch.converters import register_converter\n",
    "\n",
    "an_db = dbs['an']\n",
    "raw_db = dbs['raw']\n",
    "raw_es = load_elasticindex('es-raw.yaml')\n",
    "an_es = load_elasticindex('es-an.yaml')\n",
    "raw_db_es = BrokerSearch(raw_db, raw_es)\n",
    "an_db_es = BrokerSearch(an_db, an_es)\n",
    "\n",
    "\n",
    "hdr1 = next(iter(an_db_es('usednodes.ndkwargs.algorithm:art')))\n",
    "hdr2 = next(iter(an_db_es('usednodes.ndkwargs.algorithm:gridrec')))\n",
    "\n",
    "art = next(hdr1.data('img_tomo', stream_name='final_primary'))\n",
    "grid = next(hdr2.data('img_tomo', stream_name='final_primary'))\n",
    "\n",
    "# Compare results\n",
    "fig, axs = plt.subplots(1, 3, tight_layout=True)\n",
    "for img, ax in zip([art, grid], axs):\n",
    "    ax.imshow(img)\n",
    "axs[-1].imshow(art - grid)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
